{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z5YVNCz9mLL"
   },
   "source": [
    "# AIMET dependencies install & build\n",
    "The following group of cells installs the AIMET library for you. For more details, please see [this link](https://github.com/quic/aimet/blob/develop/packaging/google_colab_install.md).\n",
    "\n",
    "You can clone this notebook and use it in your own project. Make sure that before running these cells, you connect to a hosted environment with a GPU accelerator. (Runtime -> Change runtime -> Hardware Accelerator(GPU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Hz_C0-x_hbw"
   },
   "source": [
    "## Installing dependencies\n",
    "May prompt you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CdeL83rFt-Zy",
    "outputId": "d8a6c4ec-ceb9-4b8a-d277-a4c2c1b2b0a2"
   },
   "outputs": [],
   "source": [
    "!pip3 uninstall --yes protobuf\n",
    "!pip3 uninstall --yes tensorflow\n",
    "!apt-get update\n",
    "!apt-get install python3.6\n",
    "!apt-get install python3-dev\n",
    "!apt-get install python3-pip\n",
    "!apt-get install liblapacke liblapacke-dev\n",
    "!apt-get install wget\n",
    "!pip3 install numpy==1.16.4\n",
    "!apt-get install libgtest-dev build-essential cmake\n",
    "!pip3 --no-cache-dir install opencv-python==4.1.0.25\n",
    "!pip3 --no-cache-dir install pillow==6.2.1\n",
    "!pip3 install pytorch-ignite==0.1.0\n",
    "!wget -q https://github.com/Itseez/opencv/archive/3.1.0.tar.gz -O /tmp/3.1.0.tar.gz > /dev/null\n",
    "!tar -C /tmp -xvf /tmp/3.1.0.tar.gz > /dev/null\n",
    "%cd /tmp/opencv-3.1.0\n",
    "%mkdir release\n",
    "%cd release\n",
    "!cmake -DCMAKE_POSITION_INDEPENDENT_CODE=ON -DBUILD_SHARED_LIBS=OFF -DCMAKE_BUILD_TYPE=release -DWITH_FFMPEG=OFF -DBUILD_TESTS=OFF -DWITH_CUDA=OFF -DBUILD_PERF_TESTS=OFF -DWITH_IPP=OFF -DENABLE_PRECOMPILED_HEADERS=OFF .. > /dev/null\n",
    "!make -j16 > /dev/null\n",
    "!make -j16 install > /dev/null\n",
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
    "!apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
    "!dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
    "!apt-get update\n",
    "!wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
    "!apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
    "!apt-get update\n",
    "!apt install cuda-cublas-10-0 cuda-cufft-10-0 cuda-curand-10-0 cuda-cusolver-10-0\n",
    "!apt-get update && apt install cuda-cusparse-10-0 libcudnn7=7.6.2.24-1+cuda10.0 libnccl2=2.4.8-1+cuda10.0  cuda-command-line-tools-10.0\n",
    "!pip3 install scipy==1.1.0\n",
    "!pip3 install protobuf==3.7.1\n",
    "!pip3 install scikit-learn==0.19.1\n",
    "!pip3 install tb-nightly==1.14.0a20190517\n",
    "!pip3 install tensorboardX==1.7\n",
    "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install --upgrade pip\n",
    "!pip3 install tensorflow-gpu==1.15.0\n",
    "!pip3 install future==0.17.1\n",
    "!pip3 install tensorboard==1.14\n",
    "!pip3 install bokeh==1.2.0\n",
    "!pip3 install pandas==0.22.0\n",
    "!pip3 install holoviews==1.12.7\n",
    "!pip3 install --no-deps bokeh==1.2.0 hvplot==0.4.0\n",
    "!pip3 install jsonschema==3.1.1\n",
    "!pip3 install osqp onnx\n",
    "\n",
    "!ln -s /usr/local/cuda-10.0 /usr/local/cuda\n",
    "!apt-get update && apt-get install -y libjpeg8-dev\n",
    "!ln -s /usr/lib/x86_64-linux-gnu/libjpeg.so /usr/lib\n",
    "\n",
    "!apt install zlib1g-dev\n",
    "\n",
    "!pip3 uninstall --yes Pillow && pip3 install Pillow-SIMD==6.0.0.post0\n",
    "!pip3 uninstall --yes pytest\n",
    "!pip3 install pytest\n",
    "\n",
    "!pip3 install setuptools==41.0.1\n",
    "!pip3 install keras==2.2.4\n",
    "\n",
    "%rm -rf /usr/local/bin/python\n",
    "!ln -s /usr/bin/python3 /usr/local/bin/python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiiZL_wi_oeP"
   },
   "source": [
    "After installing the dependencies, you must restart the environment before proceeding if you are working on google colab. (Runtime -> Restart Runtime) Don't run the first cell again in the restarted runtime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdF9TK03CKiW"
   },
   "source": [
    "## AIMET build and installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKxhMkMJuNE_",
    "outputId": "ba5eecb2-3447-4e31-ca95-aa72db442ba1"
   },
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "!rm -rf aimet_code\n",
    "!mkdir aimet_code\n",
    "%cd aimet_code\n",
    "!git clone https://github.com/quic/aimet.git\n",
    "%cd aimet\n",
    "%mkdir -p ./ThirdParty/googletest\n",
    "%pushd ./ThirdParty/googletest\n",
    "!git clone https://github.com/google/googletest.git -b release-1.8.0 googletest-release-1.8.0\n",
    "%popd\n",
    "%cd /content/aimet_code\n",
    "%mkdir build\n",
    "%cd build\n",
    "!cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ../aimet\n",
    "!make -j 8\n",
    "!make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6qARmUzAZj4"
   },
   "source": [
    "## Setting up `PYTHONPATH` and `LD_LIBRARY_PATH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bknoYExJuRJm"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'/content/aimet_code/build/staging/universal/lib/python')\n",
    "sys.path.append(r'/content/aimet_code/build/staging/universal/lib/x86_64-linux-gnu')\n",
    "sys.path.append(r'/usr/local/lib/python3.6/dist-packages')\n",
    "sys.path.append(r'/content/aimet_code/build/artifacts')\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['LD_LIBRARY_PATH']+= \":/content/aimet_code/build/artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DiI-1hvAhd3"
   },
   "source": [
    "## Run unit tests\n",
    "If the installation went smoothly, all tests should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-b_VUTSuZT2",
    "outputId": "1bb289d5-c284-41d9-a9ca-7a2d8f814d8d"
   },
   "outputs": [],
   "source": [
    "%cd /content/aimet_code/build/\n",
    "!ctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsT60OxHwuVN"
   },
   "source": [
    "# Import necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VOb8Uyqqwz91",
    "outputId": "0eaf7b90-578c-4c8d-8685-b17f2ce2991f"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "import torchvision.transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from aimet_common.defs import CostMetric, CompressionScheme, GreedySelectionParameters\n",
    "from aimet_torch.defs import ChannelPruningParameters, SpatialSvdParameters, ModuleCompRatioPair\n",
    "from aimet_torch.compress import ModelCompressor\n",
    "from aimet_torch.onnx_utils import OnnxSaver\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZJ8R7fCRx_f"
   },
   "source": [
    "# Define a model and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YF98Lnf2DXg"
   },
   "outputs": [],
   "source": [
    "# Define test loader\n",
    "transformImg = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "\n",
    "test = MNIST(root='./data', train=False, download=True, transform=transformImg)\n",
    "test_loader = DataLoader(test, batch_size=1024, num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "train = MNIST(root='./data', train=True, download=True, transform=transformImg)\n",
    "train_loader = DataLoader(train, batch_size=1024, num_workers=4, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXn0f41ueDFN"
   },
   "source": [
    "Set random seed for reprodubicility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-GPWZa2eFS1"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_zQ5VelR30T"
   },
   "source": [
    "Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9-dFvJhRxsf"
   },
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):          \n",
    "\n",
    "    def __init__(self):     \n",
    "        super(LeNet5, self).__init__()\n",
    "        self.convs = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2),\n",
    "                                    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2)\n",
    "                                  )\n",
    "\n",
    "        self.linears = nn.Sequential(nn.Linear(16*5*5, 120),\n",
    "                                     nn.Linear(120, 84),\n",
    "                                     nn.Linear(84, 10)\n",
    "                                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.linears(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iRixegDe7Ot"
   },
   "source": [
    "Define functions for conducting the training and testing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-zAeCohxoEL",
    "outputId": "b0a25931-f4e7-4b50-f0a2-032579693aea"
   },
   "outputs": [],
   "source": [
    "def accuracy(out, y):\n",
    "    preds = out.argmax(dim=1, keepdim=True).squeeze()\n",
    "    correct = preds.eq(y).sum().item()\n",
    "    return correct\n",
    "\n",
    "def train_epoch(model, opt, train_loader, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    n_samples = 0\n",
    "    for x,y in train_loader:\n",
    "        opt.zero_grad()\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model.forward(x)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        epoch_acc += accuracy(out, y)\n",
    "        epoch_loss += loss.item()\n",
    "        n_samples += x.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    epoch_acc = epoch_acc / n_samples\n",
    "    epoch_loss = epoch_loss / n_samples\n",
    "\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "def test_epoch(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    n_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model.forward(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            epoch_acc += accuracy(out, y)\n",
    "            epoch_loss += loss.item()\n",
    "            n_samples += x.size(0)\n",
    "\n",
    "    epoch_acc = epoch_acc / n_samples\n",
    "    epoch_loss = epoch_loss / n_samples\n",
    "\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "def display_grayscale(tensor):\n",
    "    ''' show single tensor as grayscale image'''\n",
    "    plt.imshow(tensor, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhA5cWP0xXEk"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkkRJKxEtF0z"
   },
   "source": [
    "Define a class to apply imbalance to your datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuqRk-63tF00"
   },
   "outputs": [],
   "source": [
    "class Dataset_Preprocessor:\n",
    "    ''' class around MNIST object for applying imbalance to its dataset '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Convert imgs to tensor and normalize by mean and stddev of the training set\n",
    "        transformImg = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        \n",
    "        \n",
    "        self.dataset = MNIST(root='./data', train=True, download=True, transform=transformImg)\n",
    "        self.class_order = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #MNIST-specific\n",
    "        self.selection_dict = dict()\n",
    "        self.shuffle()\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=128, num_workers=4, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def shuffle(self):\n",
    "        ''' shuffle dataset '''\n",
    "        # generate random ordered indeces for dataset\n",
    "        datapoints = self.dataset.data.shape[0]\n",
    "        rand_idx = torch.randperm(datapoints)\n",
    "\n",
    "        # shuffle data and targets in the same way\n",
    "        self.dataset.data = self.dataset.data[rand_idx]\n",
    "        self.dataset.targets = self.dataset.targets[rand_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def keep_selection(self, target, selection):\n",
    "        ''' create imbalance in single class of a dataset '''\n",
    "\n",
    "        # get indices of imgs of target number and remove selection of the indices\n",
    "        target_mask = self.dataset.targets == target\n",
    "        selection_idx = target_mask.nonzero()[round(len(target_mask.nonzero())*selection):]\n",
    "\n",
    "        # make mask wich selects all data except for indices in selection\n",
    "        selection_mask = np.ones(len(self.dataset.data), dtype=bool)\n",
    "        selection_mask[selection_idx] = False\n",
    "\n",
    "        # apply mask to remove the selected data\n",
    "        self.dataset.data = self.dataset.data[selection_mask]\n",
    "        self.dataset.targets = self.dataset.targets[selection_mask]\n",
    "\n",
    "    \n",
    "    \n",
    "    def apply_imbalance(self):\n",
    "        ''' create imbalance in dataset according to selection dict '''\n",
    "\n",
    "        # throw away a part of the data for each class\n",
    "        for class_number, selection in self.selection_dict.items():\n",
    "            self.keep_selection(class_number, selection)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=128, num_workers=4, shuffle=True, pin_memory=True)\n",
    "        self.wrs_dataloader = self.apply_weighted_random_sampler()\n",
    "        \n",
    "        \n",
    "    def balance(self):\n",
    "        self.selection_dict = dict()\n",
    "        self.apply_imbalance()\n",
    "        return self.selection_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "    def linear_imbalance(self, rho, apply=True):\n",
    "        ''' create selection dict with linear imbalance '''\n",
    "        \n",
    "        min_examples = 1 / rho\n",
    "        \n",
    "        n_steps = len(self.class_order) - 1\n",
    "        linear_step = (1.0 - min_examples) / n_steps\n",
    "\n",
    "        # interpolate the classes between the minimum and maximum linearly\n",
    "        for i, data_class in enumerate(reversed(self.class_order)):\n",
    "            self.selection_dict[data_class] = min_examples + (i * linear_step)\n",
    "        \n",
    "        if apply:\n",
    "            self.apply_imbalance()\n",
    "\n",
    "        return self.selection_dict\n",
    "\n",
    "            \n",
    "            \n",
    "    def step_imbalance(self, rho, mu, apply=True):\n",
    "        ''' create selection dict with step imbalance '''\n",
    "        \n",
    "        min_examples = 1 / rho\n",
    "        \n",
    "        \n",
    "        n_classes = len(self.class_order)\n",
    "        step_index = int(mu * n_classes)\n",
    "\n",
    "        for i, data_class in enumerate(reversed(self.class_order)):\n",
    "            if i < step_index:\n",
    "                self.selection_dict[data_class] = min_examples\n",
    "            else:\n",
    "                self.selection_dict[data_class] = 1.0\n",
    "\n",
    "        if apply:\n",
    "            self.apply_imbalance()\n",
    "            \n",
    "        return self.selection_dict\n",
    "\n",
    "\n",
    "                  \n",
    "    def long_tailed_imbalance(self, ratio, apply=True):\n",
    "        ''' create selection dict with long-tailed imbalance '''\n",
    "        \n",
    "        # determine mu from ratio\n",
    "        mu = (1/ratio)**(1/(len(self.class_order) - 1))\n",
    "        \n",
    "        # set selection for each class according to long-tailed function, mu is in (0,1)\n",
    "        for i, data_class in enumerate(self.class_order):\n",
    "            self.selection_dict[data_class] = mu**i\n",
    "\n",
    "        if apply:\n",
    "            self.apply_imbalance()\n",
    "        \n",
    "        return self.selection_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def apply_weighted_random_sampler(self):\n",
    "        ''' \n",
    "        return dataloader using weighted random sampling\n",
    "        modified from https://discuss.pytorch.org/t/how-to-handle-imbalanced-classes/11264 \n",
    "        by user ptrblck\n",
    "        '''\n",
    "        \n",
    "        # get sample count per class\n",
    "        class_sample_count = np.unique(self.dataset.targets, return_counts=True)[1]\n",
    "        \n",
    "        weight = 1. / class_sample_count\n",
    "        \n",
    "        # define weight per sample\n",
    "        samples_weight = weight[self.dataset.targets]\n",
    "        samples_weight = torch.from_numpy(samples_weight)\n",
    "        \n",
    "        sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "        \n",
    "        # define weight usable for loss functions\n",
    "        self.weight = torch.FloatTensor(weight / weight.sum())\n",
    "        \n",
    "        return DataLoader(self.dataset, batch_size=128, num_workers=4, pin_memory=True, sampler=sampler)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot(self, title, color='r'):\n",
    "        ''' plot the imbalance created by an imbalance function '''\n",
    "        \n",
    "        plt.bar(self.selection_dict.keys(), self.selection_dict.values(), color=color)\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvQCbIEyN2w"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w97dpw3dyde"
   },
   "source": [
    "Functions for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D28i0tp6VqTZ"
   },
   "outputs": [],
   "source": [
    "# Focal Loss function taken from https://github.com/gokulprasadthekkel/pytorch-multi-class-focal-loss\n",
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight, reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight # weight parameter will act as the alpha parameter to balance class weights\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction, weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss\n",
    "\n",
    "\n",
    "    \n",
    "def train_model(train_loader, description, loss_func=\"CE\", weight=None, gamma=2, test=False, test_loader=test_loader, \n",
    "                log=False):\n",
    "    ''' train on data loader, and return trained model '''\n",
    "    \n",
    "    # Determine loss function\n",
    "    if loss_func == \"CE\":\n",
    "        criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    else:\n",
    "        FL = FocalLoss(weight=weight, gamma=gamma)\n",
    "        criterion = FL.forward\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    n_epochs = 10\n",
    "    writer = SummaryWriter(f'runs/{description}')\n",
    "    model = LeNet5().to(device)\n",
    "    opt = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "    # Train+test, log to tensorboard\n",
    "    # It's recommended to also print all the scalar values\n",
    "    for i in range(n_epochs):\n",
    "        train_acc, train_loss = train_epoch(model, opt, train_loader, criterion, device)\n",
    "        \n",
    "        if log:\n",
    "            writer.add_scalar('train/acc', train_acc, i+1)\n",
    "            writer.add_scalar('train/loss', train_loss, i+1)\n",
    "        \n",
    "        if test:\n",
    "            test_acc, test_loss = test_epoch(model, test_loader, criterion, device)\n",
    "            \n",
    "            if log:\n",
    "                writer.add_scalar('test/acc', test_acc, i+1)\n",
    "                writer.add_scalar('test/loss', test_loss, i+1)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p7dzY73mfBQ"
   },
   "source": [
    "# Model Compression\n",
    "Using Channel Pruning and Spatial SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mE-CvbnmmhMl"
   },
   "outputs": [],
   "source": [
    "# Model compressor needs an evaluation function with this specific signature\n",
    "\n",
    "def eval_callback(model, iterations, use_cuda=True):\n",
    "    model.eval()\n",
    "    epoch_acc = 0\n",
    "    n_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,(x,y) in enumerate(test_loader):\n",
    "            if use_cuda:\n",
    "                x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "\n",
    "            out = model.forward(x)\n",
    "            epoch_acc += accuracy(out, y)\n",
    "            n_samples += x.size(0)\n",
    "\n",
    "            if iterations is not None:\n",
    "                if idx == iterations:\n",
    "                    break\n",
    "        epoch_acc = epoch_acc / n_samples\n",
    "\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwJ-IiuZ0hz-"
   },
   "source": [
    "Define model compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyc281QHtF1A"
   },
   "outputs": [],
   "source": [
    "def compress(model, comp_ratio, method, data=None):\n",
    "    \"\"\"\n",
    "    Compresses a trained model to a certain ratio. Uses the user specified\n",
    "    compression method. There are two options: \"svd\" or \"prun\".\n",
    "    If using \"prun\" method, user needs to provide data.\n",
    "    Returns the compressed model and a list containing:\n",
    "    1. baseline_model_accuracy,\n",
    "    2. compressed_model_accuracy,\n",
    "    3. mac_compression_ratio, \n",
    "    4. memory_compression_ratio.\n",
    "    \"\"\"\n",
    "    input_shape = (1, 1, 28, 28)\n",
    "    greedy_params = GreedySelectionParameters(target_comp_ratio=Decimal(comp_ratio))\n",
    "    \n",
    "    if method == \"svd\":      \n",
    "        # Do not exclude anything in contrary to channel pruning\n",
    "        modules_to_ignore = []\n",
    "        auto_params = SpatialSvdParameters.AutoModeParams(greedy_params, modules_to_ignore)\n",
    "        # Delete all the parameters that don't give an error in channel pruning, but do here\n",
    "        spatial_svd_params = SpatialSvdParameters(mode=SpatialSvdParameters.Mode.auto,\n",
    "                                                              params=auto_params)\n",
    "\n",
    "        # This takes a bit\n",
    "        comp_model, stats = ModelCompressor.compress_model(model,\n",
    "                                                           input_shape=input_shape,\n",
    "                                                           eval_callback=eval_callback,\n",
    "                                                           eval_iterations=None,\n",
    "                                                           compress_scheme=CompressionScheme.spatial_svd,\n",
    "                                                           cost_metric=CostMetric.mac,\n",
    "                                                           parameters=spatial_svd_params\n",
    "                                                           )\n",
    "        \n",
    "    elif method == \"prun\":\n",
    "        if data is None:\n",
    "            print('Must provide data loader when using \"prun\"')\n",
    "            return\n",
    "        \n",
    "        # Exclude first layer from pruning\n",
    "        modules_to_ignore = [model.convs[0]]\n",
    "        auto_params = ChannelPruningParameters.AutoModeParams(greedy_params, modules_to_ignore)\n",
    "        channel_pruning_parameters = ChannelPruningParameters(mode=ChannelPruningParameters.Mode.auto,\n",
    "                                                              params=auto_params,\n",
    "                                                              data_loader=train_loader,\n",
    "                                                              num_reconstruction_samples=1024,\n",
    "                                                              allow_custom_downsample_ops=False\n",
    "                                                              )\n",
    "\n",
    "        # This takes a bit\n",
    "        comp_model, stats = ModelCompressor.compress_model(model,\n",
    "                                                           input_shape=input_shape,\n",
    "                                                           eval_callback=eval_callback,\n",
    "                                                           eval_iterations=None,\n",
    "                                                           compress_scheme=CompressionScheme.channel_pruning,\n",
    "                                                           cost_metric=CostMetric.mac,\n",
    "                                                           parameters=channel_pruning_parameters\n",
    "                                                           )\n",
    "    else:\n",
    "        print(\"Unknown method\")\n",
    "        return\n",
    "\n",
    "    compare_mod = [stats.mac_compression_ratio, \n",
    "                   stats.memory_compression_ratio]\n",
    "    \n",
    "    return comp_model, compare_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPRESS MANUAL\n",
    "# model.convs[0] = first conv layer, model.convs[3] = second conv layer\n",
    "input_shape = (1, 1, 28, 28)\n",
    "\n",
    "manual_params = SpatialSvdParameters.ManualModeParams([ModuleCompRatioPair(model.convs[0], 0.5),\n",
    "                                                           ModuleCompRatioPair(model.convs[3], 0.4)])\n",
    "\n",
    "spatial_svd_params = SpatialSvdParameters(mode=SpatialSvdParameters.Mode.manual,\n",
    "                                  params=manual_params)\n",
    "\n",
    "comp_model_svd, stats_svd = ModelCompressor.compress_model(model,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   eval_callback=eval_callback,\n",
    "                                                   eval_iterations=None,\n",
    "                                                   compress_scheme=CompressionScheme.spatial_svd,\n",
    "                                                   cost_metric=CostMetric.mac,\n",
    "                                                   parameters=spatial_svd_params,\n",
    "                                                   )\n",
    "\n",
    "\n",
    "\n",
    "manual_params = ChannelPruningParameters.ManualModeParams([ModuleCompRatioPair(model.convs[3], 0.4)])\n",
    "\n",
    "channel_pruning_parameters = ChannelPruningParameters(mode=ChannelPruningParameters.Mode.manual,\n",
    "                                                      params=manual_params,\n",
    "                                                      data_loader=train_loader,\n",
    "                                                      num_reconstruction_samples=1024,\n",
    "                                                      allow_custom_downsample_ops=False\n",
    "                                                      )\n",
    "\n",
    "comp_model, stats = ModelCompressor.compress_model(model,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   eval_callback=eval_callback,\n",
    "                                                   eval_iterations=None,\n",
    "                                                   compress_scheme=CompressionScheme.channel_pruning,\n",
    "                                                   cost_metric=CostMetric.mac,\n",
    "                                                   parameters=channel_pruning_parameters\n",
    "                                                   )\n",
    "\n",
    "# DON'T FORGET YOU CAN CHANGE cost_metric=CostMetric.mac TO cost_metric=CostMetric.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M033akVr5wb6"
   },
   "source": [
    "Define F1-score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPRKH0dX5vtu"
   },
   "outputs": [],
   "source": [
    "def model_f1_score(model, test_loader):\n",
    "    ''' compute the F1 score of a model on a test dataloader '''\n",
    "    model.eval()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model.forward(x)\n",
    "            preds = out.argmax(dim=1, keepdim=True).squeeze()\n",
    "            y_pred += preds.squeeze().tolist()\n",
    "            y_true += y.squeeze().tolist()\n",
    "    return f1_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW_XJaFxlWFk"
   },
   "source": [
    "Opening a tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "A3fkVkHYfMi9",
    "outputId": "451ec88c-4522-4397-b1f2-703ebd3d348e"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "!pip3 install tensorboard-plugin-wit\n",
    "%tensorboard --logdir ./runs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VWeGWNyy8qL"
   },
   "source": [
    "### Research Question 1\n",
    "Using a compression ratio of 0.5 on both channel pruning and spatial SVD.\n",
    "Long-tail imbalanced is used with a ratio of 10 (most frequent class appears 10 times more often than least frequent class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "4j16SWs7tF1C",
    "outputId": "88de9fa3-acb5-4388-bf4d-cb07e605a860"
   },
   "outputs": [],
   "source": [
    "# Define the dataloader\n",
    "train_imbal = Dataset_Preprocessor()\n",
    "train_imbal.long_tailed_imbalance(10)\n",
    "train_imbal_loader = train_imbal.dataloader\n",
    "\n",
    "model_bal = train_model(train_loader, test_loader, \"Balanced\")\n",
    "model_imbal = train_model(train_imbal_loader, test_loader, \"Imbalanced\")\n",
    "\n",
    "f1_bal = model_f1_score(model_bal, test_loader)\n",
    "f1_imbal = model_f1_score(model_imbal, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osGhuAjCtF1C",
    "outputId": "ad873e19-8115-484f-ed1c-b6d195dc3397",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_model_bal_svd, stats_bal = compress(model_bal, 0.5, \"svd\")\n",
    "comp_model_imbal_svd, stats_imbal = compress(model_imbal, 0.5, \"svd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76_RbddG70C1"
   },
   "source": [
    "Test F1-score of compressed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRXL7cOK726J"
   },
   "outputs": [],
   "source": [
    "f1_bal_svd = model_f1_score(comp_model_bal_svd, test_loader)\n",
    "f1_imbal_svd = model_f1_score(comp_model_imbal_svd, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw0UlLV13alk"
   },
   "source": [
    "Test accuracy between balanced and imbalanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjR7Drp-tF1C"
   },
   "outputs": [],
   "source": [
    "# SVD RESULTS\n",
    "# RATIO OF COMPRESSION IS 0.5\n",
    "# RATIO OF IMBALANCE IS 10\n",
    "print(\"------------------------BALANCED------------------------\")\n",
    "print(f\"F1-score balanced model: {f1_bal}\")\n",
    "print(f\"F1-score balanced compressed model: {f1_bal_svd}\")\n",
    "print(\"------------------------IMBALANCED------------------------\")\n",
    "print(f\"F1-score imbalanced model: {f1_imbal}\")\n",
    "print(f\"F1-score imbalanced compressed model: {f1_imbal_svd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrOYTCGxtF1D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_model_bal_prun, stats_bal = compress(model_bal, 0.5, \"prun\")\n",
    "comp_model_imbal_prun, stats_imbal = compress(model_imbal, 0.5, \"prun\")\n",
    "\n",
    "f1_bal_prun = model_f1_score(comp_model_bal_prun, test_loader)\n",
    "f1_imbal_prun = model_f1_score(comp_model_imbal_prun, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csGIOgRRtF1D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PRUNING RESULTS\n",
    "# RATIO OF COMPRESSION IS 0.5\n",
    "# RATIO OF IMBALANCE IS 10\n",
    "print(\"------------------------BALANCED------------------------\")\n",
    "print(f\"F1-score balanced model: {f1_bal}\")\n",
    "print(f\"F1-score balanced compressed model: {f1_bal_prun}\")\n",
    "print(\"------------------------IMBALANCED------------------------\")\n",
    "print(f\"F1-score imbalanced model: {f1_imbal}\")\n",
    "print(f\"F1-score imbalanced compressed model: {f1_imbal_prun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qB8KplteFXV"
   },
   "source": [
    "## Testin imbalance learning methods\n",
    "HEELLL yea (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNSFrRrItF03",
    "outputId": "111b5d8a-eaca-4850-e777-7d7b5c32f125"
   },
   "outputs": [],
   "source": [
    "# Define test loader\n",
    "transformImg = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "\n",
    "test = MNIST(root='./data', train=False, download=True, transform=transformImg)\n",
    "test_loader = DataLoader(test, batch_size=1024, num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Define train loaders\n",
    "train = Dataset_Preprocessor()\n",
    "train.long_tailed_imbalance(10) \n",
    "train_loader = train.dataloader\n",
    "train_wrs_loader = train.wrs_dataloader\n",
    "train_weight = train.weight.cuda()\n",
    "\n",
    "print(train_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "W58XhohsbOtu",
    "outputId": "1596e50e-2d64-4049-8392-cd3e0c167737"
   },
   "outputs": [],
   "source": [
    "# normal_imb_model = train_model(train_loader, \"Long-Tailed\")\n",
    "# wrs_CE_model = train_model(train_wrs_loader, \"Long-Tailed, WRS\")\n",
    "# normal_WCE_model = train_model(train_loader, \"Weighted CE\", weight=train_weight)\n",
    "# wrs_WCE_model = train_model(train_wrs_loader, \"WRS, Weighted CE\", weight=train_weight)\n",
    "gamma_half = train_model(train_loader, \"Focal Loss\", loss_func=\"FL\", weight=train_weight, gamma=0.19)\n",
    "gamma_one = train_model(train_loader, \"Focal Loss\", loss_func=\"FL\", weight=train_weight, gamma=0.15)\n",
    "\n",
    "gamma_one_half = train_model(train_loader, \"Focal Loss\", loss_func=\"FL\", weight=train_weight, gamma=0.25)\n",
    "gamma_two = train_model(train_wrs_loader, \"WRS, Focal Loss\", loss_func=\"FL\", weight=train_weight, gamma=0.21)\n",
    "\n",
    "\n",
    "print(\"Gamma: 0.4 ;\", our_f1_score(gamma_half, test_loader))\n",
    "print(\"Gamma: 0.3 ;\", our_f1_score(gamma_one, test_loader))\n",
    "print(\"Gamma: 0.2 ;\", our_f1_score(gamma_one_half, test_loader))\n",
    "print(\"Gamma: 0.1 ;\", our_f1_score(gamma_two, test_loader))\n",
    "\n",
    "# print(\"Just Imbalance:\", our_f1_score(normal_imb_model, test_loader))\n",
    "# print(\"WRS, normal CE:\", our_f1_score(wrs_CE_model, test_loader))\n",
    "# print(\"Normal loader, WCE:\", our_f1_score(normal_WCE_model, test_loader))\n",
    "# print(\"WRS, WCE:\", our_f1_score(wrs_WCE_model, test_loader))\n",
    "# print(\"Normal Loader, FL:\", our_f1_score(normal_FL_model, test_loader))\n",
    "# print(\"WRS, FL:\", our_f1_score(wrs_FL_model, test_loader))\n",
    "\n",
    "# out:\n",
    "# Just Imbalance: 0.9464903384582831\n",
    "\n",
    "# WRS, normal CE: 0.9533586754650354\n",
    "# Normal loader, WCE: 0.9595584417399692\n",
    "# WRS, WCE: 0.897340612775242\n",
    "# Normal Loader, FL: 0.9251946954174868\n",
    "# WRS, FL: 0.9048888067949405\n",
    "# Normal Loader, FL (gamma=3): 0.8874900486210671\n",
    "# WRS, FL (gamma=1): 0.9412699364062872\n",
    "# Normal Loader, FL (gamma=1): 0.9519792810834111\n",
    "# WRS, FL (gamma=3): 0.8853290644996112\n",
    "\n",
    "# Gamma: 0.5 ; 0.9520905676432927\n",
    "# Gamma: 1.0 ; 0.9489965087640392\n",
    "# Gamma: 1.5 ; 0.9320343237494246\n",
    "# Gamma: 2.0 ; 0.8816604889961507\n",
    "# Gamma: 0.4 ; 0.9521100294383325\n",
    "# Gamma: 0.3 ; 0.9553254760710955\n",
    "# Gamma: 0.2 ; 0.9622722563627012\n",
    "# Gamma: 0.1 ; 0.9546977824804741\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6uMJERazkHK"
   },
   "source": [
    "## Test 2\n",
    "Varying the long-tailed imbalance but keeping the compress ratio constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "miXvZCj4tF1B",
    "outputId": "1223467a-4889-41d1-ff86-3b610c7a1c54"
   },
   "outputs": [],
   "source": [
    "def imbal_ratio_tester(ratio_compr=0.5, seeds=[42]):\n",
    "    ''' test how different compression ratios behave under various imbalance ratios '''\n",
    "    imb_ratios = [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "    # test the same model for multiple seeds\n",
    "    for seed in seeds:\n",
    "        f1_ogs = []\n",
    "        f1_svds = []\n",
    "        f1_pruns = []\n",
    "        set_seed(seed)\n",
    "        for ratio in imb_ratios:\n",
    "            # create dataloader\n",
    "            train = Dataset_Preprocessor()\n",
    "            train.long_tailed_imbalance(ratio)\n",
    "            train_imbal_loader = train_imbal.dataloader\n",
    "\n",
    "            # train model\n",
    "            model_name = f\"RQ2. Imbalance ratio: {ratio}, run: {seed}\"\n",
    "            model_imbal = train_model(train_imbal_loader, test_loader, model_name)\n",
    "\n",
    "            # compress model\n",
    "            comp_model_svd, stats_imbal_svd = compress(model_imbal, ratio_compr, \"svd\")\n",
    "            comp_model_prun, stats_imbal_prun = compress(model_imbal, ratio_compr, \"prun\", train_imbal_loader)\n",
    "\n",
    "            # store F1-scores\n",
    "            f1_ogs.append(model_f1_score(model_imbal, test_loader))\n",
    "            f1_svds.append(model_f1_score(comp_model_svd, test_loader))\n",
    "            f1_pruns.append(model_f1_score(comp_model_prun, test_loader))\n",
    "\n",
    "        # print F1-scores in a table\n",
    "        print(\"|Imbalance\\t|F1 OG Model\\t|F1 SVD Model\\t|F1 PRUN Model\\t|\")\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        for i in range(len(ratios)):\n",
    "            print(f\"|{ratios[i]}\\t\\t|{f1_ogs[i]}\\t|{f1_svds[i]}\\t|{f1_pruns[i]}\\t|\")\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "    \n",
    "    return f1_ogs, f1_svds, f1_pruns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "imbal_ratio_tester(seeds=[420, 893, 666])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P0zhJ0Rbqs2"
   },
   "source": [
    "## Test 3\n",
    "\n",
    "Varying the compression ratio imbalance while keeping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fH60M79XbzDL",
    "outputId": "f56de190-1de8-447f-a96c-5bd1c4f73383"
   },
   "outputs": [],
   "source": [
    "def comp_ratio_tester(dataloader, n_runs=1, loss_func='CE', description=\"\", weight=None, gamma=1):\n",
    "    comp_ratios = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    seeds = [31]\n",
    "\n",
    "    for seed in seeds:\n",
    "        set_seed(seed)\n",
    "        f1_svds = []\n",
    "        f1_pruns = []\n",
    "        model = train_model(dataloader, description, weight=weight, loss_func=loss_func, gamma=gamma)\n",
    "        for comp_ratio in comp_ratios:\n",
    "\n",
    "            model_svd, stats_imbal_svd = compress(model, comp_ratio, \"svd\")\n",
    "            model_prun, stats_imbal_prun = compress(model, comp_ratio, \"prun\", train_imbal_loader)\n",
    "\n",
    "            f1_svds.append(model_f1_score(model_svd, test_loader))\n",
    "            f1_pruns.append(model_f1_score(model_prun, test_loader))\n",
    "\n",
    "        print(f\"model {description}; seed: {seed}\")\n",
    "        print(\"|Imbalance\\t|F1 SVD Model\\t|F1 PRUN Model\\t|\")\n",
    "        print(\"--------------------------------------------------------------\")\n",
    "        for i in range(len(comp_ratios)):\n",
    "            print(f\"|{comp_ratios[i]}\\t|{f1_svds[i]}\\t|{f1_pruns[i]}\\t|\")\n",
    "            print(\"------------------------------------------------------------\")\n",
    "\n",
    "    return f1_svds, f1_pruns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# comp_ratio_tester(train_loader, description=\"Baseline\")\n",
    "comp_ratio_tester(train_wrs_loader, description=\"WRS\")\n",
    "# comp_ratio_tester(train_loader, description=\"WCE\", weight=train_weight)\n",
    "# comp_ratio_tester(train_wrs_loader, description=\"WRS, Weighted CE\", weight=train_weight)\n",
    "# comp_ratio_tester(train_loader, description=\"Focal Loss, gamma=1\", loss_func=\"FL\", weight=train_weight, gamma=1)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "our_aimet_ready.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
